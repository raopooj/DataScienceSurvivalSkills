{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ac1e4dd",
   "metadata": {},
   "source": [
    "# Exercise 8) Part 1: Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e2658",
   "metadata": {},
   "source": [
    "## Loading the Fashion-MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset using Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f0f8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Shape of training images?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a517393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of training labels?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467a770",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min(), x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb51b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale values to [0, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e91b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min(), x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e1e89",
   "metadata": {},
   "source": [
    "## Let's have a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84509a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First training sample\n",
    "idx = \n",
    "img = \n",
    "label = \n",
    "\n",
    "# Plot image with class label\n",
    "plt.imshow(img, cmap=\"binary\")\n",
    "plt.title(f\"{label}: {class_names[label]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=\"binary\")\n",
    "    plt.xlabel(class_names[y_train[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ded56b",
   "metadata": {},
   "source": [
    "## Model evaluation 1) Training & validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31662ba",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/blog/2016/model-evaluation-selection-part3/holdout-validation_01.png\" width=\"1000\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6897f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# Split into 80% training and 20% validation set\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e47f7",
   "metadata": {},
   "source": [
    "## Building a Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    # MLP with 2 hidden layers (256, 128 units) and \"relu\" activation function\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "# Choose optimizer & loss function and compile the model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679063c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model for 50 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60db881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"training accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"validation accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006d63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(history.history[\"loss\"], label=\"training loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488a657",
   "metadata": {},
   "source": [
    "**How to interpret the loss curve?**\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:786/format:webp/1*lARssDbZVTvk4S-Dk1g-eA.png\" width=500 align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be89400",
   "metadata": {},
   "source": [
    "## Check how well the model does on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for test data\n",
    "# y_predicted = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc8111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction for a test image \n",
    "img = x_test[12]\n",
    "pred = y_predicted[12]\n",
    "true_class = y_test[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47633d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a2ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_names[true_class], true_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f458bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b148b08",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1391d9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why does the prediction look like this? -> softmax activation, 10 classes\n",
    "for i in range(10):\n",
    "    print(f\"{pred[i]:.2f} - {class_names[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2abfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which class has the highest prediction?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e323a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn all predictions into predicted classes (0, 1, 2 ... or 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee96e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    \n",
    "    # Get true class for current image\n",
    "    true_class = class_names[y_test[i]]\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction = y_predicted[i]\n",
    "    predicted_class = class_names[np.argmax(prediction)]\n",
    "    \n",
    "    text = f\"{predicted_class} (true: {true_class})\"\n",
    "    \n",
    "    color = \"green\" if predicted_class == true_class else \"red\"\n",
    "    \n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_test[i], cmap=\"binary\")\n",
    "    plt.xlabel(text, color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74538d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy for test dataset\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Test accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix for test dataset\n",
    "\n",
    "\n",
    "\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted class\")\n",
    "plt.ylabel(\"True class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c14b3d",
   "metadata": {},
   "source": [
    "## Model evaluation 2) k-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c93916",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/blog/2016/model-evaluation-selection-part3/kfold.png\" width=\"600\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6496c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y), (x_test, y_test) = fashion_mnist.load_data()\n",
    "x = x / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up 5-fold cross-validation\n",
    "\n",
    "\n",
    "accuracy_list = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(x_train):\n",
    "    \n",
    "    # Training folds\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Validation fold\n",
    "    \n",
    "    \n",
    "    \n",
    "    # MLP\n",
    "    model = build_model()\n",
    "    \n",
    "    # Train\n",
    "    model.fit(x_train, y_train, epochs=20, batch_size=128, verbose=0)\n",
    "    # Evaluate\n",
    "    val_loss, val_acc = model.evaluate(x_val, y_val, verbose=0)\n",
    "    \n",
    "    print(f\"Fold {fold}: Accuracy {val_acc:.4f}\")\n",
    "    accuracy_list.append(val_acc)\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda6216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average validation accuracy\n",
    "\n",
    "print(f\"Mean validation accuracy (5-fold CV): {mean_val_accuracy:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f64749",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "\n",
    "# Part 2: Image segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b664f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as io\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another version of BAGLS dataset:\n",
    "# More data than in MiniBAGLS, images cropped to 224 x 224 pixels\n",
    "data_path = \"C:/Data/Datasets/BAGLS_4096/\"\n",
    "file_names = os.listdir(data_path)\n",
    "file_names.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd0ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths of images and masks\n",
    "images = [data_path + x for x in file_names if not x.endswith('seg.png')]\n",
    "masks = [x.split('.')[0]+'_seg.png' for x in images]\n",
    "\n",
    "print(images[0])\n",
    "print(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test dataset\n",
    "\n",
    "\n",
    "print(len(train_im), len(test_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d74054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_paths, mask_paths):\n",
    "    # ===== Load images =====\n",
    "\n",
    "    # scale values to [0,1] range\n",
    "\n",
    "    # Add color dimension (1 because grayscale)\n",
    "\n",
    "    \n",
    "    # ==== Load masks =====\n",
    "\n",
    "    # scale values to [0,1] range\n",
    "\n",
    "    # Add color dimension (1 because grayscale)\n",
    "\n",
    "    \n",
    "    print(f'Loaded images of shape {X.shape} and masks of shape {y.shape}')\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d783fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train, y_train = load_data(train_im, train_masks)\n",
    "X_test, y_test = load_data(test_im, test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training image with mask (glottis)\n",
    "def show_image_and_mask(x, y):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(x[...,0], cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(y[...,0], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "show_image_and_mask(X_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b46003",
   "metadata": {},
   "source": [
    "## Build U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d68ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Input, MaxPool2D, UpSampling2D, Activation, BatchNormalization, Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b2b205",
   "metadata": {},
   "source": [
    "**Original U-Net:**\n",
    "\n",
    "Ronneberger, O., Fischer, P., & Brox, T. (2015, October). U-net: Convolutional networks for biomedical image segmentation. In _International Conference on Medical image computing and computer-assisted intervention_ (pp. 234-241). Springer, Cham.\n",
    "    \n",
    "<img align=\"left\" src=https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified U-Net\n",
    "# (2 encoder & decoder blocks, 16 initial filters)\n",
    "\n",
    "def conv_block(x, num_filters):\n",
    "    # Convolutional layer with kernel size 3, padding \"same\"\n",
    "\n",
    "    # BatchNormalization layer\n",
    "\n",
    "    # Activation function \"relu\"\n",
    "\n",
    "    \n",
    "    # Convolutional layer with kernel size 3, padding \"same\"\n",
    "\n",
    "    # BatchNormalization layer\n",
    "\n",
    "    # Activation function \"relu\"\n",
    "\n",
    "    return x\n",
    "\n",
    "def build_Unet(filters=16, num_classes=1):\n",
    "    # Input layer\n",
    "\n",
    "    \n",
    "    # Encoder\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Bottleneck\n",
    "    \n",
    "    \n",
    "    # Decoder\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Output layer\n",
    "    \n",
    "    \n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = build_Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc1c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in unet.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        print(layer.output_shape)  # (batch_size, height, width, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b120d46",
   "metadata": {},
   "source": [
    "## Train U-Net\n",
    "\n",
    "A great library for image segmentation: https://segmentation-models.readthedocs.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195fd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install segmentation-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models.metrics import iou_score\n",
    "from segmentation_models.losses import dice_loss\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),  # Define optimizer and learning rate\n",
    "              loss=dice_loss,                      # Dice loss function\n",
    "              metrics=[iou_score])                 # Intersection over Union (IoU) & Dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a577d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with batch size 64, for 50 epochs\n",
    "\n",
    "\n",
    "\n",
    "# Save model and history\n",
    "model.save(\"unet.h5\")\n",
    "pd.DataFrame(history.history).to_csv(\"history.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c98653",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.read_csv(\"history.csv\")\n",
    "\n",
    "# Plot loss for each epoch\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(121)\n",
    "plt.plot(hist[\"loss\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"training loss\")\n",
    "\n",
    "# Plot IoU score for each epoch\n",
    "plt.subplot(122)\n",
    "plt.plot(hist[\"iou_score\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"training IoU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f534fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "loaded_model = load_model(\"unet.h5\", custom_objects={\"iou_score\": iou_score, \"dice_loss\": dice_loss}, compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7942a1f",
   "metadata": {},
   "source": [
    "## Check predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted masks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1974b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "\n",
    "img = X_test[idx]\n",
    "mask = y_test[idx]\n",
    "pred = predictions[idx]\n",
    "\n",
    "# IoU score\n",
    "iou = iou_score(mask, pred)\n",
    "\n",
    "# Plot image, ground truth and prediction\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Image')\n",
    "plt.imshow(img[...,0], cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Ground truth')\n",
    "plt.imshow(mask[...,0], cmap='gray')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Prediction, IoU = {:.2f}'.format(iou))\n",
    "plt.imshow(pred[...,0], cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
